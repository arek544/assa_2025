{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S0Ko8Ok6E7IT"
      },
      "outputs": [],
      "source": [
        "# Tutorial 1: Dictionary learning assignment\n",
        "# ======================================================\n",
        "#\n",
        "# This tutorial guides students through learning a dictionary from acoustic data.\n",
        "# They will extract patches, train a dictionary, reconstruct, and analyze sparsity.\n",
        "\n",
        "# Section 0: Setup\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import DictionaryLearning, MiniBatchDictionaryLearning, PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from skimage.util import view_as_windows\n",
        "from scipy.signal import detrend\n",
        "\n",
        "np.random.seed(42)\n",
        "plt.rcParams[\"figure.dpi\"] = 130\n",
        "\n",
        "# Section 1: Load your Data\n",
        "\n",
        "\n",
        "# Section 2: Patch Extraction\n",
        "def extract_patches_2d_st(data2d, patch_size=(16, 32), stride=(8, 16)):\n",
        "    Ps, Pt = patch_size\n",
        "    Ss, St = stride\n",
        "    windows = view_as_windows(data2d, (Ps, Pt), step=(Ss, St))\n",
        "    patches = windows.reshape(-1, Ps, Pt)\n",
        "    return patches\n",
        "\n",
        "def stack_patches(data, patch_size=(16, 32), stride=(8, 16), max_patches=None):\n",
        "    if data.ndim == 2:\n",
        "        patches = extract_patches_2d_st(data, patch_size, stride)\n",
        "    else:\n",
        "        plist = [extract_patches_2d_st(d, patch_size, stride) for d in data]\n",
        "        patches = np.concatenate(plist, axis=0)\n",
        "    if max_patches and patches.shape[0] > max_patches:\n",
        "        idx = np.random.choice(patches.shape[0], max_patches, replace=False)\n",
        "        patches = patches[idx]\n",
        "    return patches\n",
        "\n",
        "PATCH_SIZE = (16, 32)\n",
        "STRIDE = (8, 16)\n",
        "MAX_PATCHES = 20000\n",
        "patches = stack_patches(data, PATCH_SIZE, STRIDE, max_patches=MAX_PATCHES)\n",
        "print(\"Patches:\", patches.shape)\n",
        "\n",
        "# Section 3: Preprocessing\n",
        "Ps, Pt = PATCH_SIZE\n",
        "X = patches.reshape(patches.shape[0], -1)\n",
        "X_detrended = [detrend(p, axis=1, type='constant').reshape(-1) for p in patches]\n",
        "X = np.asarray(X_detrended, dtype=np.float32)\n",
        "\n",
        "scaler = StandardScaler(with_mean=True, with_std=True)\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_train, X_val = train_test_split(X_scaled, test_size=0.1, random_state=42)\n",
        "print(\"Train/Val:\", X_train.shape, X_val.shape)\n",
        "\n",
        "# Section 4: Dictionary Learning (students tune hyperparameters)\n",
        "N_COMPONENTS = 128\n",
        "ALPHA = 1.0\n",
        "MAX_ITER = 100\n",
        "\n",
        "learner = DictionaryLearning(\n",
        "    n_components=N_COMPONENTS,\n",
        "    alpha=ALPHA,\n",
        "    max_iter=MAX_ITER,\n",
        "    fit_algorithm='cd',\n",
        "    transform_algorithm='lasso_lars',\n",
        "    transform_alpha=ALPHA,\n",
        "    random_state=42,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "D_codes = learner.fit_transform(X_train)\n",
        "D_atoms = learner.components_\n",
        "print(\"Atoms:\", D_atoms.shape)\n",
        "\n",
        "# Section 5: Reconstruction\n",
        "C_val = learner.transform(X_val)\n",
        "X_val_rec = C_val @ learner.components_\n",
        "X_val_rec = scaler.inverse_transform(X_val_rec)\n",
        "X_val_unscaled = scaler.inverse_transform(X_val)\n",
        "\n",
        "mse = np.mean((X_val_unscaled - X_val_rec)**2)\n",
        "print(f\"Reconstruction MSE: {mse:.4e}\")\n",
        "\n",
        "# Section 6: Visualization\n",
        "def show_atoms(atoms, patch_size, n_rows=6, n_cols=8, title=\"Dictionary Atoms\"):\n",
        "    Ps, Pt = patch_size\n",
        "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(1.2*n_cols, 1.2*n_rows))\n",
        "    for i, ax in enumerate(axes.flat):\n",
        "        if i >= atoms.shape[0]:\n",
        "            ax.axis('off'); continue\n",
        "        im = ax.imshow(atoms[i].reshape(Ps, Pt), aspect='auto', origin='lower', cmap='viridis')\n",
        "        ax.set_xticks([]); ax.set_yticks([])\n",
        "    plt.suptitle(title)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "show_atoms(D_atoms, PATCH_SIZE)\n",
        "\n"
      ]
    }
  ]
}