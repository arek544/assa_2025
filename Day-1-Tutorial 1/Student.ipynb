{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfc2f181-7136-405e-b9be-1480d3456042",
   "metadata": {},
   "source": [
    "# Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdda55e-8505-4113-be36-e6ce3ad77d03",
   "metadata": {},
   "source": [
    "It's exam season ! We collected samples from 200 students that had a free day before their last exam and some decided to throw a party.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "Load the dataset, it contains datas on 200 \"students\" : their age, number of hours they worked, number of pints they had the night before and final grade (0-20).\n",
    "\n",
    "Before going further, back to the basics : compute the minimum, maximum and mean of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21a98b79-81b0-4fd2-b7d2-3932ec0534e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "489413c0-7ef1-4d71-9bc6-c53a833193c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = np.load(\"dataset.npy\")\n",
    "\n",
    "columns_names = ['age', 'hours', 'pints', 'grade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6162e5-afa6-4787-a6c8-08f850afaa3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3c4d02-f0cf-477e-85b2-ea224022eac2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c855c2a-3df6-4f81-b509-8eec9bee5a33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b23a011-1f64-4fc6-a004-a75309ce042f",
   "metadata": {},
   "source": [
    "## A tale of prediction\n",
    "\n",
    "Machine learning is mostly used to predict the output of a given system provided a known input. The prediction itself can take different forms,\n",
    "require more or less postprocessing to be usable, but in the end, it's a guess.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "To explore a bit this world, let's turn to the dataset and check the link between the number of hours worked and the number of pints...\n",
    "Plot the former against the latter, it's always a good idea to visualize your data.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "Note that there's no reason the samples would be correctly ordered, so it's probably better to use <code>plt.scatter</code> instead of <code>plt.plot</code>. An insteresting representation trick when you might have overlapping data points is to use the <code>alpha</code> parameter to make the plot translucent and better visualize possible clusters (<code>alpha=0.2</code> should work alright).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "id": "c7b8ade1-8d9c-4b94-8358-a5c69776c327",
   "metadata": {},
   "outputs": [],
   "source": [
    "age = ds[:,0]\n",
    "hours = ds[:,1]\n",
    "pints = ds[:,2]\n",
    "grade = ds[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e49748b-2f81-41c4-a087-f3b8abd86f1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d36500-85c6-4612-91d4-221d0f2b24f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dcb9cd1d-a1c1-496a-86e8-b48c48ffa488",
   "metadata": {},
   "source": [
    "Let's try to build a model to represent that relationship\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "A <b>model</b> is an idealized representation of reality. The goal is to capture the <b>essential behaviour</b> and discard noise effects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42796c2f-5374-4662-b5f2-15e5efabf6cc",
   "metadata": {},
   "source": [
    "Here, we could try a 1- or 2-parameter model (constant or linear with an intercept). If we go down this path, we already know that we will not capture all of the observations. To determine the parameters\n",
    "We can do that in 3 different ways:\n",
    "\n",
    "- Compute the Least Mean Squares regresssion using the formula $M^TM p = M^T y$ with $p = [a_N, a_{N-1},\\ldots,a_1,a_0]$ the vector of coefficients and $M = [x^N|x^{N_1}|\\ldots|x|1]$ and $(x, y)$ are input/output **vectors**\n",
    "- Use numpy's ``polyfit`` function\n",
    "- Use ``sklearn`` LinearRegressor class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7eafc53-cd6e-4425-b309-001692fe7237",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    Try a 3-parameter polynomial fit on the proposed data (<code>numpy.polyfit</code>). Plot the result against the data<br/>\n",
    "What can you observe ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278349b0-73eb-4578-8240-cf96756c4a39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129fd648-0628-4a01-ab40-4d2f77117aa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f256531a-3641-4590-9e77-1cfe7ce91550",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c3f1e92-513c-4e8a-82e4-6bec56f852a0",
   "metadata": {},
   "source": [
    "It looks like we're missing parts of the events\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "This is typical from <b>Underfitting</b> :<ul>\n",
    "    <li>The model is too simple to accurately represent the data</li>\n",
    "    <li>It doesn't capture noise but misses information</li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "Try increasing the polynomial degree to 3, 4 or 10 to fit data better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b39a174-8582-482a-b838-7f55664a5710",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f9633a-1683-4507-989f-bbcce3e98100",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c742b2c-8f67-4513-9853-b8bf648e7a7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3f0a747-f6d3-4fea-be91-bfb891a08c70",
   "metadata": {},
   "source": [
    "Hum... this time, we see some improvement. The model seems to somewhat capture the data for a polynomial of degree 4.\n",
    "Between a 4th order and a 10th order polynomial, there's no much improvement though. So, what should we use ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b421a635-f46f-457d-9ab2-9088d33f7063",
   "metadata": {},
   "source": [
    "##Â How close from the \"truth\" ?\n",
    "\n",
    "Here, we're playing with simulated data, the \"ground truth\" is known.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "Load the <code>real_pint_data</code> file and plot it alongside the previous fits, it contains denoised data and will show us what the actual phenomenon looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14d7dec9-d228-492f-9011-6a08572ed616",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = np.load(\"real_pint_data.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488c6b29-eb48-4f1f-925a-34018a4dbcf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2897c56d-2cd4-4b53-8377-794ee4394dd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b052ac1-42b2-4406-8f00-e88100b0d155",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4b9ac0-a228-4809-814b-00ed95aff30b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb43f4a9-de4b-470a-93df-908f57fd52aa",
   "metadata": {},
   "source": [
    "OK so it seems that a 4th order fit is enough here... \n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    Higher order models might be OK  at first sight but they do have an inherent issue : <b>they overfit</b>.\n",
    "That means:\n",
    "    <ul>\n",
    "        <li>the large number of parameters allow them to fit the proposed data <i>too well</i> and they capture noise</li>\n",
    "        <li>they are not able to <b>generalize</b> : if presented new inputs, they won't be able to  correctly predict an output.</li>\n",
    "    </ul>\n",
    "\n",
    "\n",
    "Note that there's always a model large enough to perfectly match all presented datapoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b151ebde-55f1-4859-9402-f32e6c10c8ed",
   "metadata": {},
   "source": [
    "## Generalization, prediction accuracy\n",
    "\n",
    "Let's try to measure the accuracy of our prediction.\n",
    "The easy way to do that is to compute an error measure on the predicted data vs real data.\n",
    "\n",
    "$$\\epsilon = \\frac{1}{N}\\sum_i L(y_i, f(x_i))$$\n",
    "\n",
    "with the model $f$ linking input $x_i$ to a prediction that must be compared to the observed data $y_i$ through a \"distance\" $L$.\n",
    "\n",
    "Let's use the squared error : $L(y_{true}, y_{pred}) = (y_{true} - y_{pred})^2$\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "Compute the error for the different polynomial orders we tried, plot a graph of the error versus the polynomial degree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9cf28f3-b82d-47e8-bd3b-c84b87ba4dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(x, y, model):\n",
    "    # code here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f1663d-3ee3-4efb-b9e9-aa2a32f513c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c4966e-fbae-4c0b-b21d-9d4bf22c74f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b853a0-05c2-4258-b2d2-61c44bf8a741",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167e0dcf-fe0f-44af-8ba6-26c38cc1cf88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96e54db4-c6aa-45a7-8f1e-0b344e270b82",
   "metadata": {},
   "source": [
    "This error we computed is called the *train* error, because it is the error observed between the developped model and the data we use to adjust it.\n",
    "\n",
    "In terms of machine learning, what we're actually looking for is not just to correctly approximate a set of observations but also to be able to handle information that we've never seen before.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "Let's extend the example to a larger dataset. We have the records of 1000 students in the file <code>full_ds</code>. Load it, plot the scatter of the work hours/pints relationship and use your models trained on 200 points to match the 1000 points. If the model is correct, it should generalize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a38ebff-ae06-448c-9dce-80539785b44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fullds = np.load('full_ds.npy')\n",
    "age1k = fullds[:,0]\n",
    "hours1k = fullds[:,1]\n",
    "pints1k = fullds[:,2]\n",
    "grade1k = fullds[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dba8bf-7ecb-4f92-ac16-8b3fb7620f82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6052fc69-b550-4f45-994a-7543727412a5",
   "metadata": {},
   "source": [
    "Let's plot the evolution of the error on the large dataset with increasing polynomial degree. For the sake of getting a nice graph, retrain your polynomial models for degrees going from 0 to 8 and recompute the errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be763b7-46af-46b4-9857-d9ecc98b1ae7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2619f5bb-e281-4dd8-9409-03aadc232551",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1c5907-c5ff-4e8b-ad95-ed1f9d06aca0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1018e820-91e9-4f88-8be0-008f581b6064",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34450b0b-c6a8-4fcc-b03f-16ffc2dada38",
   "metadata": {},
   "source": [
    "For each model there's a sweet spot and this graph is perfect to find it. The model is optimal when the test error is at a minimum and usually it is just after a drop in the train error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b93cfd-4ebf-4541-98ea-7a7c17d8d140",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Let's play some more with this by changing how many of the records we use to train the regressions. We'll keep p=4, join the two datasets together and take 10%, 20%, 30% etc... of this dataset to train and the rest to evaluate the quality of the training.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "There's a useful function to do that in scikit-learn : <code>sklearn.model_selection.train_test_split</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b170cccd-761d-4f35-a49c-8f5ef1d9ac3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75e2fa4-26f0-492a-9dfa-7fbd1bf4e6cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737f2ff2-9fa6-49ad-b8ef-d4b69ea829a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb0cd03-60e4-4566-b5cf-eaf1a60a8f25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1145aea9-7f87-4d7a-bcff-18b8a634ff90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe9bdaa-cdfb-40f1-b085-f68d04da1fdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df2efa7c-79c7-4efb-a317-41a35b0b08d0",
   "metadata": {},
   "source": [
    "# Looking at the full dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acf2c42-268e-4467-ad78-11d11588456c",
   "metadata": {},
   "source": [
    "Let's stop focusing on that hours/pint relationship and go towards the full dataset.\n",
    "\n",
    "You've seen how even linear models can manage to represent complex links between features. Now, how to predict the grade based on the other columns ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df7214e-cafc-4199-9d26-31dd4b9412d0",
   "metadata": {},
   "source": [
    "Scikit-learn is a very complete toolbox for all sorts of data processing and machine learning tasks (it even has simple neural nets to do some preliminary analyses).\n",
    "    \n",
    "In the follow up, we'll stick to this linear models but using a built-in regressor based on Stochastic Gradient Descent. You'll find this term again in the Neural Net realm as it is a rather efficient optimisation strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a08ec04-ed51-4d59-a375-b5d2eacdb4c9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "From <code>sklearn.linear_model</code>, import and instantiate a <code>SGDRegressor</code> object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "id": "45d8f7d4-a7c9-4555-bd9b-04e03b22e704",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a73217f-ee0d-4838-8e3a-0f1e43798475",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d46124dc-5765-44e9-87d6-0d6d0e9ad659",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">Join the age, hours and pints vectors into a matrix, 1 sample per row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c03a95-d719-470c-b19f-436bfe4c9745",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e227d3cb-5e9e-4c2e-a11f-5ccedad8d134",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090f4ae4-4391-4f3b-94da-d217bb460148",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96c13a37-dc11-4248-ac9f-78c5464ec82d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">Use the method <code>fit</code> of the regressor to learn from the inputs/grade couples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622f1243-2227-4ab4-950a-5b6cbc873552",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd7c479-7710-4265-bed9-e1334d66da33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cbccd211-e26c-46c2-a79b-92e6e9e1a665",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">Join the age, hours and pints vectors of the 1k sample dataset the same way and pass it to the <code>predict</code> method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1271f083-6bb8-4557-af68-45665c18613c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec572f52-f526-444a-afe3-3b4fff450c9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b80d3e62-fb02-4f1e-9512-8c363ff9ba06",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">Plot a scatter of the predicted_grade versus the actual grades from the 1k sample dataset. If your regression worked well, the points should align on the $x=y$ line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1655de-b287-4be8-b706-f93105dffe4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adbdfb2-6076-438a-8c0d-1e14048b6943",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78463852-aa77-41b7-9ba3-10fc71f50218",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29daafc4-6f6b-4d13-a036-404ed5dbd23f",
   "metadata": {},
   "source": [
    "Hmmm... You don't have to believe me right away but I tell you : this dataset **is** linearly separable, so this should work. What is wrong then ?\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">It is always a good idea to normalize your inputs and outputs when dealing with data.</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">Using the <code>StandardScaler</code> and <code>MinMaxScaler</code> from <code>sklearn.preprocessing</code> transform your input and output data both for the training and testing datasets.<div class=\"alert alert-block alert-info\">Join the age, hours and pints vectors into a matrix, 1 sample per row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "id": "7afdea77-ed33-4319-9415-fc27d20023b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0826d11c-1f48-4fe6-953e-e9c925783185",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9a3958-2ab3-419b-bb60-38df8b78081b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8149317f-01e3-4af8-861a-5447285c29f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "852bfc40-6568-4d9f-95e9-36f848d17514",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">Retrain a <code>SGDRegressor</code> on the normalized data and draw the same scatter plot as before. What can you conclude ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad479866-1594-4728-8ae1-f67751e9429e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86607abd-ba04-4397-94a3-8c7f0a2e3997",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306564f0-3bfc-40f9-9a56-05232e773950",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15e60bc7-d0bb-4053-983e-5e2be1f61e9c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">Some samples are still out of the line, look into scikit-learn documentation and the previous work on the hours/pint relationship to find a way to match these anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6ec4fa-1f17-4b28-9c46-b500c07add02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956bb9c4-99da-4e86-9efc-2d6266e40dca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fdce0d-92a9-4cb0-a346-cccce033b1c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcab679b-bdc2-4c48-9df6-ddee14ae84e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d84c3e-3d51-45df-94eb-f2ac1d8ef7c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8284e1-5711-4f6b-af7f-c7a7f33f4a0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6332d0-5fc0-446d-9ea8-db1c21b5848c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771d58e1-5458-45d4-a458-f3a16c8d3fb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
